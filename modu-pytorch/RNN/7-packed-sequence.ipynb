{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "시퀀스 데이터는 대표적으로 텍스트 데이터와 오디오 데이터가 있다.</br>\n",
    "여기서는 길이가 매번 다른 시퀀스 데이터를 하나의 배치로 만드는 방법을 살펴본다.</br> \n",
    "\n",
    "패딩 방법은 모든 시퀀스를 가장 긴 시퀀스에 길이에 맞추고, 패딩을 채워넣는다.</br>\n",
    "컴퓨터가 이해하기 쉽지만, 계산하지 않아도 될 패드부분을 계산한다는 단점이 있다.</br>\n",
    "pad_sequence 함수를 사용</br>\n",
    "pack_padded_sequence 함수는 padded -> packed로 변환한다.</br>\n",
    "\n",
    "패킹 방법은 시퀀스에 길이를 저장해서 각각의 배치고 만든다. 이경우 반드시 길이 내림차순으로 정렬되어야 한다.</br>\n",
    "불필요한 계산이 없고 공간을 효율적으로 쓸 수 있지만, 내림차순으로 정렬해야 하고 구현이 좀 더 복잡하다.</br> \n",
    "pack_sequence 함수를 사용</br>\n",
    "pad_packed_sequence 함수는 packed -> padded로 변환한다.</br>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Random word from random word generator\n",
    "data = ['hello world',\n",
    "        'midnight',\n",
    "        'calculation',\n",
    "        'path',\n",
    "        'short circuit']\n",
    "\n",
    "# Make dictionary\n",
    "char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token\n",
    "char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n",
    "print('char_set:', char_set)\n",
    "print('char_set length:', len(char_set))\n",
    "\n",
    "# Convert character to index and\n",
    "# Make list of tensors\n",
    "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
    "\n",
    "# Check converted result\n",
    "for sequence in X:\n",
    "    print(sequence)\n",
    "\n",
    "# Make length tensor (will be used later in 'pack_padded_sequence' function)\n",
    "lengths = [len(seq) for seq in X]\n",
    "print('lengths:', lengths)\n",
    "\n",
    "# Make a Tensor of shape (Batch x Maximum_Sequence_Length)\n",
    "padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n",
    "print(padded_sequence)\n",
    "print(padded_sequence.shape)\n",
    "\n",
    "# Sort by descending lengths\n",
    "sorted_idx = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n",
    "sorted_X = [X[idx] for idx in sorted_idx]\n",
    "\n",
    "# Check converted result\n",
    "for sequence in sorted_X:\n",
    "    print(sequence)\n",
    "\n",
    "packed_sequence = pack_sequence(sorted_X)\n",
    "print(packed_sequence)\n",
    "\n",
    "# one-hot embedding using PaddedSequence\n",
    "eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n",
    "embedded_tensor = eye[padded_sequence]\n",
    "print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)\n",
    "\n",
    "# one-hot embedding using PackedSequence\n",
    "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
    "print(embedded_packed_seq.data.shape)\n",
    "\n",
    "# declare RNN\n",
    "rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)\n",
    "\n",
    "# Try out PaddedSequence\n",
    "rnn_output, hidden = rnn(embedded_tensor)\n",
    "print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n",
    "print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)\n",
    "\n",
    "# Try out PackedSequence\n",
    "rnn_output, hidden = rnn(embedded_packed_seq)\n",
    "print(rnn_output.data.shape)\n",
    "print(hidden.data.shape)\n",
    "\n",
    "# Try out pad_packed_sequence\n",
    "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
    "print(unpacked_sequence.shape)\n",
    "print(seq_lengths)\n",
    "\n",
    "# Construct embedded_padded_sequence\n",
    "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
    "print(embedded_padded_sequence.shape)\n",
    "\n",
    "# Try out pack_padded_sequence\n",
    "sorted_lengths = sorted(lengths, reverse=True)\n",
    "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
    "print(new_packed_sequence.data.shape)\n",
    "print(new_packed_sequence.batch_sizes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}